{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install -U scikit-learn scipy matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('well_header0.csv')\n",
    "tvd=df_original['TVD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('well_header_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EPAssetsId</th>\n",
       "      <th>Surf_Township</th>\n",
       "      <th>Surf_Range</th>\n",
       "      <th>Surf_Section</th>\n",
       "      <th>Surf_Longitude</th>\n",
       "      <th>Surf_Latitude</th>\n",
       "      <th>BH_Range</th>\n",
       "      <th>GroundElevation</th>\n",
       "      <th>KBElevation</th>\n",
       "      <th>...</th>\n",
       "      <th>PSACAreaCode_AB5</th>\n",
       "      <th>PSACAreaCode_AB7</th>\n",
       "      <th>PSACAreaCode_SK2</th>\n",
       "      <th>PSACAreaName_Central Alberta</th>\n",
       "      <th>PSACAreaName_East Central Alberta</th>\n",
       "      <th>PSACAreaName_Foothills</th>\n",
       "      <th>PSACAreaName_Foothills Front</th>\n",
       "      <th>PSACAreaName_Northwestern Alberta</th>\n",
       "      <th>PSACAreaName_Southeastern Alberta</th>\n",
       "      <th>PSACAreaName_Southwestern Saskatchewan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905529</td>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>-1.209427</td>\n",
       "      <td>1.476994</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.149104</td>\n",
       "      <td>-0.151524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.886241</td>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217531</td>\n",
       "      <td>1.472307</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.235332</td>\n",
       "      <td>-0.234411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.903415</td>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217585</td>\n",
       "      <td>1.472192</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.229486</td>\n",
       "      <td>-0.231503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.897201</td>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217867</td>\n",
       "      <td>1.466949</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.165911</td>\n",
       "      <td>-0.174063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.916208</td>\n",
       "      <td>1.523589</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>-1.114272</td>\n",
       "      <td>-1.237129</td>\n",
       "      <td>1.512330</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.498401</td>\n",
       "      <td>-0.484527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>6726</td>\n",
       "      <td>0.942196</td>\n",
       "      <td>-0.523509</td>\n",
       "      <td>-0.889929</td>\n",
       "      <td>-1.494172</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>-0.546636</td>\n",
       "      <td>-0.888531</td>\n",
       "      <td>-0.099413</td>\n",
       "      <td>-0.101355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>6727</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>-0.523509</td>\n",
       "      <td>-0.889929</td>\n",
       "      <td>-1.494172</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>-0.546687</td>\n",
       "      <td>-0.888531</td>\n",
       "      <td>-0.100143</td>\n",
       "      <td>-0.101355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>6728</td>\n",
       "      <td>0.935376</td>\n",
       "      <td>-0.957741</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>-1.399197</td>\n",
       "      <td>-0.430784</td>\n",
       "      <td>-0.990001</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.268604</td>\n",
       "      <td>3.259213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>6729</td>\n",
       "      <td>0.933248</td>\n",
       "      <td>-1.019775</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>1.450050</td>\n",
       "      <td>-0.423012</td>\n",
       "      <td>-1.001156</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.345332</td>\n",
       "      <td>3.313744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>6730</td>\n",
       "      <td>0.933247</td>\n",
       "      <td>-1.019775</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>1.450050</td>\n",
       "      <td>-0.423143</td>\n",
       "      <td>-1.001458</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.332909</td>\n",
       "      <td>3.313744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6731 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  EPAssetsId  Surf_Township  Surf_Range  Surf_Section  \\\n",
       "0              0    0.905529       1.461555    1.101729      0.690251   \n",
       "1              1    0.886241       1.461555    1.101729      0.215376   \n",
       "2              2    0.903415       1.461555    1.101729      0.215376   \n",
       "3              3    0.897201       1.461555    1.101729      0.215376   \n",
       "4              4    0.916208       1.523589    1.101729     -1.114272   \n",
       "...          ...         ...            ...         ...           ...   \n",
       "6726        6726    0.942196      -0.523509   -0.889929     -1.494172   \n",
       "6727        6727    0.942197      -0.523509   -0.889929     -1.494172   \n",
       "6728        6728    0.935376      -0.957741   -1.686592     -1.399197   \n",
       "6729        6729    0.933248      -1.019775   -1.686592      1.450050   \n",
       "6730        6730    0.933247      -1.019775   -1.686592      1.450050   \n",
       "\n",
       "      Surf_Longitude  Surf_Latitude  BH_Range  GroundElevation  KBElevation  \\\n",
       "0          -1.209427       1.476994  1.100705        -0.149104    -0.151524   \n",
       "1          -1.217531       1.472307  1.100705        -0.235332    -0.234411   \n",
       "2          -1.217585       1.472192  1.100705        -0.229486    -0.231503   \n",
       "3          -1.217867       1.466949  1.100705        -0.165911    -0.174063   \n",
       "4          -1.237129       1.512330  1.100705        -0.498401    -0.484527   \n",
       "...              ...            ...       ...              ...          ...   \n",
       "6726        0.350202      -0.546636 -0.888531        -0.099413    -0.101355   \n",
       "6727        0.350202      -0.546687 -0.888531        -0.100143    -0.101355   \n",
       "6728       -0.430784      -0.990001 -1.684226         3.268604     3.259213   \n",
       "6729       -0.423012      -1.001156 -1.684226         3.345332     3.313744   \n",
       "6730       -0.423143      -1.001458 -1.684226         3.332909     3.313744   \n",
       "\n",
       "      ...  PSACAreaCode_AB5  PSACAreaCode_AB7  PSACAreaCode_SK2  \\\n",
       "0     ...               0.0               0.0               0.0   \n",
       "1     ...               0.0               0.0               0.0   \n",
       "2     ...               0.0               0.0               0.0   \n",
       "3     ...               0.0               0.0               0.0   \n",
       "4     ...               0.0               0.0               0.0   \n",
       "...   ...               ...               ...               ...   \n",
       "6726  ...               0.0               0.0               0.0   \n",
       "6727  ...               0.0               0.0               0.0   \n",
       "6728  ...               0.0               0.0               0.0   \n",
       "6729  ...               0.0               0.0               0.0   \n",
       "6730  ...               0.0               0.0               0.0   \n",
       "\n",
       "      PSACAreaName_Central Alberta  PSACAreaName_East Central Alberta  \\\n",
       "0                              0.0                                0.0   \n",
       "1                              0.0                                0.0   \n",
       "2                              0.0                                0.0   \n",
       "3                              0.0                                0.0   \n",
       "4                              0.0                                0.0   \n",
       "...                            ...                                ...   \n",
       "6726                           0.0                                0.0   \n",
       "6727                           0.0                                0.0   \n",
       "6728                           0.0                                0.0   \n",
       "6729                           0.0                                0.0   \n",
       "6730                           0.0                                0.0   \n",
       "\n",
       "      PSACAreaName_Foothills  PSACAreaName_Foothills Front  \\\n",
       "0                        0.0                           1.0   \n",
       "1                        0.0                           1.0   \n",
       "2                        0.0                           1.0   \n",
       "3                        0.0                           1.0   \n",
       "4                        0.0                           1.0   \n",
       "...                      ...                           ...   \n",
       "6726                     0.0                           0.0   \n",
       "6727                     0.0                           0.0   \n",
       "6728                     0.0                           1.0   \n",
       "6729                     0.0                           1.0   \n",
       "6730                     0.0                           1.0   \n",
       "\n",
       "      PSACAreaName_Northwestern Alberta  PSACAreaName_Southeastern Alberta  \\\n",
       "0                                   0.0                                0.0   \n",
       "1                                   0.0                                0.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "6726                                0.0                                1.0   \n",
       "6727                                0.0                                1.0   \n",
       "6728                                0.0                                0.0   \n",
       "6729                                0.0                                0.0   \n",
       "6730                                0.0                                0.0   \n",
       "\n",
       "      PSACAreaName_Southwestern Saskatchewan  \n",
       "0                                        0.0  \n",
       "1                                        0.0  \n",
       "2                                        0.0  \n",
       "3                                        0.0  \n",
       "4                                        0.0  \n",
       "...                                      ...  \n",
       "6726                                     0.0  \n",
       "6727                                     0.0  \n",
       "6728                                     0.0  \n",
       "6729                                     0.0  \n",
       "6730                                     0.0  \n",
       "\n",
       "[6731 rows x 643 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surf_Township</th>\n",
       "      <th>Surf_Range</th>\n",
       "      <th>Surf_Section</th>\n",
       "      <th>Surf_Longitude</th>\n",
       "      <th>Surf_Latitude</th>\n",
       "      <th>BH_Range</th>\n",
       "      <th>GroundElevation</th>\n",
       "      <th>KBElevation</th>\n",
       "      <th>TotalDepth</th>\n",
       "      <th>DaysDrilling</th>\n",
       "      <th>...</th>\n",
       "      <th>PSACAreaCode_AB5</th>\n",
       "      <th>PSACAreaCode_AB7</th>\n",
       "      <th>PSACAreaCode_SK2</th>\n",
       "      <th>PSACAreaName_Central Alberta</th>\n",
       "      <th>PSACAreaName_East Central Alberta</th>\n",
       "      <th>PSACAreaName_Foothills</th>\n",
       "      <th>PSACAreaName_Foothills Front</th>\n",
       "      <th>PSACAreaName_Northwestern Alberta</th>\n",
       "      <th>PSACAreaName_Southeastern Alberta</th>\n",
       "      <th>PSACAreaName_Southwestern Saskatchewan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>-1.209427</td>\n",
       "      <td>1.476994</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.149104</td>\n",
       "      <td>-0.151524</td>\n",
       "      <td>0.351672</td>\n",
       "      <td>-0.065173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217531</td>\n",
       "      <td>1.472307</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.235332</td>\n",
       "      <td>-0.234411</td>\n",
       "      <td>0.288238</td>\n",
       "      <td>-0.065173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217585</td>\n",
       "      <td>1.472192</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.229486</td>\n",
       "      <td>-0.231503</td>\n",
       "      <td>0.281593</td>\n",
       "      <td>-0.098614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.461555</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>-1.217867</td>\n",
       "      <td>1.466949</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.165911</td>\n",
       "      <td>-0.174063</td>\n",
       "      <td>0.334152</td>\n",
       "      <td>-0.132054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.523589</td>\n",
       "      <td>1.101729</td>\n",
       "      <td>-1.114272</td>\n",
       "      <td>-1.237129</td>\n",
       "      <td>1.512330</td>\n",
       "      <td>1.100705</td>\n",
       "      <td>-0.498401</td>\n",
       "      <td>-0.484527</td>\n",
       "      <td>0.383087</td>\n",
       "      <td>-0.265818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>-0.523509</td>\n",
       "      <td>-0.889929</td>\n",
       "      <td>-1.494172</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>-0.546636</td>\n",
       "      <td>-0.888531</td>\n",
       "      <td>-0.099413</td>\n",
       "      <td>-0.101355</td>\n",
       "      <td>-0.578087</td>\n",
       "      <td>0.102032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>-0.523509</td>\n",
       "      <td>-0.889929</td>\n",
       "      <td>-1.494172</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>-0.546687</td>\n",
       "      <td>-0.888531</td>\n",
       "      <td>-0.100143</td>\n",
       "      <td>-0.101355</td>\n",
       "      <td>-0.573253</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>-0.957741</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>-1.399197</td>\n",
       "      <td>-0.430784</td>\n",
       "      <td>-0.990001</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.268604</td>\n",
       "      <td>3.259213</td>\n",
       "      <td>1.514022</td>\n",
       "      <td>-0.165495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>-1.019775</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>1.450050</td>\n",
       "      <td>-0.423012</td>\n",
       "      <td>-1.001156</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.345332</td>\n",
       "      <td>3.313744</td>\n",
       "      <td>1.059715</td>\n",
       "      <td>-0.265818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>-1.019775</td>\n",
       "      <td>-1.686592</td>\n",
       "      <td>1.450050</td>\n",
       "      <td>-0.423143</td>\n",
       "      <td>-1.001458</td>\n",
       "      <td>-1.684226</td>\n",
       "      <td>3.332909</td>\n",
       "      <td>3.313744</td>\n",
       "      <td>1.461462</td>\n",
       "      <td>-0.165495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6731 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Surf_Township  Surf_Range  Surf_Section  Surf_Longitude  Surf_Latitude  \\\n",
       "0          1.461555    1.101729      0.690251       -1.209427       1.476994   \n",
       "1          1.461555    1.101729      0.215376       -1.217531       1.472307   \n",
       "2          1.461555    1.101729      0.215376       -1.217585       1.472192   \n",
       "3          1.461555    1.101729      0.215376       -1.217867       1.466949   \n",
       "4          1.523589    1.101729     -1.114272       -1.237129       1.512330   \n",
       "...             ...         ...           ...             ...            ...   \n",
       "6726      -0.523509   -0.889929     -1.494172        0.350202      -0.546636   \n",
       "6727      -0.523509   -0.889929     -1.494172        0.350202      -0.546687   \n",
       "6728      -0.957741   -1.686592     -1.399197       -0.430784      -0.990001   \n",
       "6729      -1.019775   -1.686592      1.450050       -0.423012      -1.001156   \n",
       "6730      -1.019775   -1.686592      1.450050       -0.423143      -1.001458   \n",
       "\n",
       "      BH_Range  GroundElevation  KBElevation  TotalDepth  DaysDrilling  ...  \\\n",
       "0     1.100705        -0.149104    -0.151524    0.351672     -0.065173  ...   \n",
       "1     1.100705        -0.235332    -0.234411    0.288238     -0.065173  ...   \n",
       "2     1.100705        -0.229486    -0.231503    0.281593     -0.098614  ...   \n",
       "3     1.100705        -0.165911    -0.174063    0.334152     -0.132054  ...   \n",
       "4     1.100705        -0.498401    -0.484527    0.383087     -0.265818  ...   \n",
       "...        ...              ...          ...         ...           ...  ...   \n",
       "6726 -0.888531        -0.099413    -0.101355   -0.578087      0.102032  ...   \n",
       "6727 -0.888531        -0.100143    -0.101355   -0.573253      0.035150  ...   \n",
       "6728 -1.684226         3.268604     3.259213    1.514022     -0.165495  ...   \n",
       "6729 -1.684226         3.345332     3.313744    1.059715     -0.265818  ...   \n",
       "6730 -1.684226         3.332909     3.313744    1.461462     -0.165495  ...   \n",
       "\n",
       "      PSACAreaCode_AB5  PSACAreaCode_AB7  PSACAreaCode_SK2  \\\n",
       "0                  0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0   \n",
       "...                ...               ...               ...   \n",
       "6726               0.0               0.0               0.0   \n",
       "6727               0.0               0.0               0.0   \n",
       "6728               0.0               0.0               0.0   \n",
       "6729               0.0               0.0               0.0   \n",
       "6730               0.0               0.0               0.0   \n",
       "\n",
       "      PSACAreaName_Central Alberta  PSACAreaName_East Central Alberta  \\\n",
       "0                              0.0                                0.0   \n",
       "1                              0.0                                0.0   \n",
       "2                              0.0                                0.0   \n",
       "3                              0.0                                0.0   \n",
       "4                              0.0                                0.0   \n",
       "...                            ...                                ...   \n",
       "6726                           0.0                                0.0   \n",
       "6727                           0.0                                0.0   \n",
       "6728                           0.0                                0.0   \n",
       "6729                           0.0                                0.0   \n",
       "6730                           0.0                                0.0   \n",
       "\n",
       "      PSACAreaName_Foothills  PSACAreaName_Foothills Front  \\\n",
       "0                        0.0                           1.0   \n",
       "1                        0.0                           1.0   \n",
       "2                        0.0                           1.0   \n",
       "3                        0.0                           1.0   \n",
       "4                        0.0                           1.0   \n",
       "...                      ...                           ...   \n",
       "6726                     0.0                           0.0   \n",
       "6727                     0.0                           0.0   \n",
       "6728                     0.0                           1.0   \n",
       "6729                     0.0                           1.0   \n",
       "6730                     0.0                           1.0   \n",
       "\n",
       "      PSACAreaName_Northwestern Alberta  PSACAreaName_Southeastern Alberta  \\\n",
       "0                                   0.0                                0.0   \n",
       "1                                   0.0                                0.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "6726                                0.0                                1.0   \n",
       "6727                                0.0                                1.0   \n",
       "6728                                0.0                                0.0   \n",
       "6729                                0.0                                0.0   \n",
       "6730                                0.0                                0.0   \n",
       "\n",
       "      PSACAreaName_Southwestern Saskatchewan  \n",
       "0                                        0.0  \n",
       "1                                        0.0  \n",
       "2                                        0.0  \n",
       "3                                        0.0  \n",
       "4                                        0.0  \n",
       "...                                      ...  \n",
       "6726                                     0.0  \n",
       "6727                                     0.0  \n",
       "6728                                     0.0  \n",
       "6729                                     0.0  \n",
       "6730                                     0.0  \n",
       "\n",
       "[6731 rows x 641 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df.drop(['Unnamed: 0', 'EPAssetsId'], axis = 1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df,tvd,test_size=0.2,random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1,tvd,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-73fee4830dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using StandardScaler()\n",
    "#scaler = StandardScaler()\n",
    "scaler = QuantileTransformer()\n",
    "scaler.fit(X_train)  # doctest: +SKIP\n",
    "X_train_s = scaler.transform(X_train)  # doctest: +SKIP\n",
    "# apply same transformation to test data\n",
    "X_test_s = scaler.transform(X_test)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175555356886.94745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train,y_train)\n",
    "pred= lin_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test,pred)\n",
    "linrmse=np.sqrt(lin_mse)\n",
    "\n",
    "\n",
    "lin_reg.fit(X_train_s,y_train)\n",
    "pred_s= lin_reg.predict(X_test_s)\n",
    "lin_mse_s = mean_squared_error(y_test,pred_s)\n",
    "linrmse_s=np.sqrt(lin_mse_s)\n",
    "\n",
    "linrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980030011755.4928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linrmse_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.18716581067672"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train,y_train)\n",
    "pred_rf= rf_reg.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test,pred_rf)\n",
    "rfrmse=np.sqrt(rf_mse)\n",
    "\n",
    "rf_reg.fit(X_train_s,y_train)\n",
    "pred_s= lin_reg.predict(X_test_s)\n",
    "rfmse_s = mean_squared_error(y_test,pred_s)\n",
    "rfrmse_s=np.sqrt(rfmse_s)\n",
    "\n",
    "rfrmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980030011755.4928"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfrmse_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.1926882944855"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "ab_reg.fit(X_train,y_train)\n",
    "pred_ab= ab_reg.predict(X_test)\n",
    "ab_mse = mean_squared_error(y_test,pred_ab)\n",
    "abrmse=np.sqrt(ab_mse)\n",
    "abrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178.11831496191766"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_reg = GradientBoostingRegressor()\n",
    "gd_reg.fit(X_train,y_train)\n",
    "pred_gd= ab_reg.predict(X_test)\n",
    "gd_mse = mean_squared_error(y_test,pred_gd)\n",
    "gdrmse=np.sqrt(gd_mse)\n",
    "gdrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.1926882944855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdh_reg = HistGradientBoostingRegressor()\n",
    "gdh_reg.fit(X_train,y_train)\n",
    "pred_gdh= ab_reg.predict(X_test)\n",
    "gdh_mse = mean_squared_error(y_test,pred_gdh)\n",
    "gdhrmse=np.sqrt(gdh_mse)\n",
    "gdhrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malauddin\\.conda\\envs\\tenserflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.0931913252386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ann_reg = MLPRegressor()\n",
    "ann_reg.fit(X_train,y_train)\n",
    "pred_ann= ann_reg.predict(X_test)\n",
    "ann_mse = mean_squared_error(y_test,pred_ann)\n",
    "annrmse=np.sqrt(ann_mse)\n",
    "annrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using StandardScaler()\n",
    "#scaler = QuantileTransformer()\n",
    "#scaler.fit(X_train)  # doctest: +SKIP\n",
    "#X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "# apply same transformation to test data\n",
    "#X_test = scaler.transform(X_test)  # doctest: +SKIP\n",
    "# Using StandardScaler()\n",
    "#scaler1 = StandardScaler()\n",
    "#scaler1.fit(y_train)  # doctest: +SKIP\n",
    "#y_train = y_train/y_train.max()  # doctest: +SKIP\n",
    "# apply same transformation to test data\n",
    "#y_test = y_test/y_test.max()  # doctest: +SKIP\n",
    "#X_train\n",
    "#y_train\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.53159339892635"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "              \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ann_reg = MLPRegressor(\n",
    "                        hidden_layer_sizes=(100,100),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "                        learning_rate='adaptive', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=False,\n",
    "                        random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "                        early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "ann_reg.fit(X_train,y_train)\n",
    "pred_ann= ann_reg.predict(X_test)\n",
    "ann_mse = mean_squared_error(y_test,pred_ann)\n",
    "annrmse=np.sqrt(ann_mse)\n",
    "annrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4307 samples, validate on 1077 samples\n",
      "Epoch 1/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 1381091.7087 - val_loss: 77001.5730\n",
      "Epoch 2/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 45929.0447 - val_loss: 31136.4879\n",
      "Epoch 3/500\n",
      "4307/4307 [==============================] - 1s 137us/step - loss: 22249.1297 - val_loss: 19381.9813\n",
      "Epoch 4/500\n",
      "4307/4307 [==============================] - 0s 100us/step - loss: 14546.2398 - val_loss: 15607.8905\n",
      "Epoch 5/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 11290.7006 - val_loss: 12169.4543\n",
      "Epoch 6/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 9131.6817 - val_loss: 10885.9223\n",
      "Epoch 7/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 7552.6490 - val_loss: 9174.2812\n",
      "Epoch 8/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 6618.0039 - val_loss: 8176.3315\n",
      "Epoch 9/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 5713.9488 - val_loss: 7503.0668\n",
      "Epoch 10/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 5112.8798 - val_loss: 7254.0584\n",
      "Epoch 11/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 4679.1204 - val_loss: 6602.1471\n",
      "Epoch 12/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 4411.3609 - val_loss: 6339.9362\n",
      "Epoch 13/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 3903.9408 - val_loss: 6058.9487\n",
      "Epoch 14/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 3571.3295 - val_loss: 6093.6296\n",
      "Epoch 15/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 3272.8740 - val_loss: 5570.5324\n",
      "Epoch 16/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 3001.2379 - val_loss: 5222.1637\n",
      "Epoch 17/500\n",
      "4307/4307 [==============================] - 1s 141us/step - loss: 2836.1811 - val_loss: 5181.6539\n",
      "Epoch 18/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 2644.0385 - val_loss: 5030.7031\n",
      "Epoch 19/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 2532.8246 - val_loss: 4822.2995\n",
      "Epoch 20/500\n",
      "4307/4307 [==============================] - 1s 121us/step - loss: 2372.1227 - val_loss: 4609.5492\n",
      "Epoch 21/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 2283.3612 - val_loss: 4484.4992\n",
      "Epoch 22/500\n",
      "4307/4307 [==============================] - 0s 84us/step - loss: 2102.4757 - val_loss: 4448.9993\n",
      "Epoch 23/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 2104.5794 - val_loss: 4487.9244\n",
      "Epoch 24/500\n",
      "4307/4307 [==============================] - 1s 124us/step - loss: 2008.3144 - val_loss: 4451.8107\n",
      "Epoch 25/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 1917.9292 - val_loss: 3964.0727\n",
      "Epoch 26/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 1870.0280 - val_loss: 3988.5311\n",
      "Epoch 27/500\n",
      "4307/4307 [==============================] - 1s 132us/step - loss: 1900.5237 - val_loss: 4024.7514\n",
      "Epoch 28/500\n",
      "4307/4307 [==============================] - 0s 106us/step - loss: 1713.6606 - val_loss: 3856.0578\n",
      "Epoch 29/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 1707.4543 - val_loss: 3873.7190\n",
      "Epoch 30/500\n",
      "4307/4307 [==============================] - 1s 137us/step - loss: 1709.0444 - val_loss: 3848.6182\n",
      "Epoch 31/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 1675.2589 - val_loss: 3973.5550\n",
      "Epoch 32/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 1663.6496 - val_loss: 3658.8310\n",
      "Epoch 33/500\n",
      "4307/4307 [==============================] - 1s 116us/step - loss: 1534.7478 - val_loss: 3666.2442\n",
      "Epoch 34/500\n",
      "4307/4307 [==============================] - 0s 114us/step - loss: 1535.3423 - val_loss: 3551.8531\n",
      "Epoch 35/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 1537.7029 - val_loss: 3497.6651\n",
      "Epoch 36/500\n",
      "4307/4307 [==============================] - 0s 100us/step - loss: 1440.7151 - val_loss: 3542.4661\n",
      "Epoch 37/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 1517.1788 - val_loss: 3462.8363\n",
      "Epoch 38/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 1453.4358 - val_loss: 3385.6378\n",
      "Epoch 39/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 1324.9724 - val_loss: 3722.9937\n",
      "Epoch 40/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 1333.0505 - val_loss: 3401.3441\n",
      "Epoch 41/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 1438.1209 - val_loss: 3248.0709\n",
      "Epoch 42/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 1328.0667 - val_loss: 3178.2254\n",
      "Epoch 43/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 1246.5620 - val_loss: 3392.8672\n",
      "Epoch 44/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 1242.6762 - val_loss: 3384.2100\n",
      "Epoch 45/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 1221.3105 - val_loss: 3350.5570\n",
      "Epoch 46/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 1200.9129 - val_loss: 3102.0458\n",
      "Epoch 47/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 1143.3072 - val_loss: 3203.6292\n",
      "Epoch 48/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 1234.0495 - val_loss: 3359.2422\n",
      "Epoch 49/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 1253.3410 - val_loss: 3370.3324\n",
      "Epoch 50/500\n",
      "4307/4307 [==============================] - 1s 128us/step - loss: 1123.5866 - val_loss: 3175.8526\n",
      "Epoch 51/500\n",
      "4307/4307 [==============================] - 0s 108us/step - loss: 1172.9697 - val_loss: 3190.1550\n",
      "Epoch 52/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 1233.9687 - val_loss: 3622.9581\n",
      "Epoch 53/500\n",
      "4307/4307 [==============================] - 0s 100us/step - loss: 1106.8999 - val_loss: 3152.0667\n",
      "Epoch 54/500\n",
      "4307/4307 [==============================] - 0s 115us/step - loss: 996.9460 - val_loss: 3088.7802\n",
      "Epoch 55/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 1146.8927 - val_loss: 2771.9972\n",
      "Epoch 56/500\n",
      "4307/4307 [==============================] - 0s 95us/step - loss: 1099.7550 - val_loss: 2746.9859\n",
      "Epoch 57/500\n",
      "4307/4307 [==============================] - 1s 123us/step - loss: 1032.4772 - val_loss: 2715.3935\n",
      "Epoch 58/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 1036.4050 - val_loss: 3534.7881\n",
      "Epoch 59/500\n",
      "4307/4307 [==============================] - 0s 84us/step - loss: 1067.8108 - val_loss: 3082.6156\n",
      "Epoch 60/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 1016.2549 - val_loss: 3493.3542\n",
      "Epoch 61/500\n",
      "4307/4307 [==============================] - 1s 119us/step - loss: 1157.1386 - val_loss: 3102.2832\n",
      "Epoch 62/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 1054.9343 - val_loss: 2675.2066\n",
      "Epoch 63/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 940.2757 - val_loss: 2696.0762\n",
      "Epoch 64/500\n",
      "4307/4307 [==============================] - 1s 143us/step - loss: 1005.0875 - val_loss: 2695.2025\n",
      "Epoch 65/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 970.4662 - val_loss: 2623.3496\n",
      "Epoch 66/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 969.0694 - val_loss: 2742.1374\n",
      "Epoch 67/500\n",
      "4307/4307 [==============================] - 1s 127us/step - loss: 1004.9550 - val_loss: 2652.4525\n",
      "Epoch 68/500\n",
      "4307/4307 [==============================] - 0s 115us/step - loss: 1014.8632 - val_loss: 2610.0646\n",
      "Epoch 69/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 990.3087 - val_loss: 3086.9164\n",
      "Epoch 70/500\n",
      "4307/4307 [==============================] - 0s 106us/step - loss: 924.7248 - val_loss: 2559.4233\n",
      "Epoch 71/500\n",
      "4307/4307 [==============================] - 1s 131us/step - loss: 937.7479 - val_loss: 2775.3414\n",
      "Epoch 72/500\n",
      "4307/4307 [==============================] - 0s 96us/step - loss: 1008.8752 - val_loss: 2607.0609\n",
      "Epoch 73/500\n",
      "4307/4307 [==============================] - 0s 93us/step - loss: 889.7339 - val_loss: 2711.8552\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4307/4307 [==============================] - 1s 126us/step - loss: 892.4784 - val_loss: 2957.9305\n",
      "Epoch 75/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 828.6101 - val_loss: 2380.1195\n",
      "Epoch 76/500\n",
      "4307/4307 [==============================] - 0s 84us/step - loss: 874.8127 - val_loss: 2721.5094\n",
      "Epoch 77/500\n",
      "4307/4307 [==============================] - 0s 108us/step - loss: 926.0173 - val_loss: 2418.8461\n",
      "Epoch 78/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 870.8554 - val_loss: 2525.3222\n",
      "Epoch 79/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 925.5618 - val_loss: 3624.6716\n",
      "Epoch 80/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 900.8731 - val_loss: 2455.2467\n",
      "Epoch 81/500\n",
      "4307/4307 [==============================] - 1s 121us/step - loss: 867.2974 - val_loss: 2503.9128\n",
      "Epoch 82/500\n",
      "4307/4307 [==============================] - 0s 84us/step - loss: 870.7293 - val_loss: 2901.7782\n",
      "Epoch 83/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 807.8743 - val_loss: 2399.2425\n",
      "Epoch 84/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 890.9439 - val_loss: 2338.0402\n",
      "Epoch 85/500\n",
      "4307/4307 [==============================] - 1s 119us/step - loss: 825.4363 - val_loss: 2392.9549\n",
      "Epoch 86/500\n",
      "4307/4307 [==============================] - 0s 106us/step - loss: 835.0261 - val_loss: 2399.3825\n",
      "Epoch 87/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 812.0975 - val_loss: 2364.9981\n",
      "Epoch 88/500\n",
      "4307/4307 [==============================] - 1s 124us/step - loss: 836.3328 - val_loss: 2354.9975\n",
      "Epoch 89/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 892.1340 - val_loss: 3256.8466\n",
      "Epoch 90/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 872.6379 - val_loss: 2343.0813\n",
      "Epoch 91/500\n",
      "4307/4307 [==============================] - 1s 126us/step - loss: 795.4018 - val_loss: 2637.8915\n",
      "Epoch 92/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 869.0840 - val_loss: 2408.6051\n",
      "Epoch 93/500\n",
      "4307/4307 [==============================] - 0s 95us/step - loss: 764.7407 - val_loss: 2363.8321\n",
      "Epoch 94/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 729.8444 - val_loss: 2278.5191\n",
      "Epoch 95/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 815.1073 - val_loss: 2359.3979\n",
      "Epoch 96/500\n",
      "4307/4307 [==============================] - 0s 87us/step - loss: 766.6855 - val_loss: 2307.7859\n",
      "Epoch 97/500\n",
      "4307/4307 [==============================] - 0s 95us/step - loss: 778.5858 - val_loss: 2593.3857\n",
      "Epoch 98/500\n",
      "4307/4307 [==============================] - 1s 137us/step - loss: 775.0699 - val_loss: 2317.9996\n",
      "Epoch 99/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 785.8113 - val_loss: 2199.2188\n",
      "Epoch 100/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 716.2547 - val_loss: 2157.0192\n",
      "Epoch 101/500\n",
      "4307/4307 [==============================] - 1s 157us/step - loss: 801.1773 - val_loss: 2419.3007\n",
      "Epoch 102/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 796.1751 - val_loss: 2293.4840\n",
      "Epoch 103/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 980.4094 - val_loss: 2163.1316\n",
      "Epoch 104/500\n",
      "4307/4307 [==============================] - 1s 117us/step - loss: 810.6562 - val_loss: 2236.4980\n",
      "Epoch 105/500\n",
      "4307/4307 [==============================] - 1s 130us/step - loss: 707.4581 - val_loss: 2340.5480\n",
      "Epoch 106/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 746.0870 - val_loss: 2198.2752\n",
      "Epoch 107/500\n",
      "4307/4307 [==============================] - 1s 131us/step - loss: 689.9747 - val_loss: 2430.0503\n",
      "Epoch 108/500\n",
      "4307/4307 [==============================] - 1s 134us/step - loss: 723.0874 - val_loss: 2084.3291\n",
      "Epoch 109/500\n",
      "4307/4307 [==============================] - 0s 106us/step - loss: 794.8596 - val_loss: 2276.0466\n",
      "Epoch 110/500\n",
      "4307/4307 [==============================] - 1s 128us/step - loss: 716.2493 - val_loss: 2393.4620\n",
      "Epoch 111/500\n",
      "4307/4307 [==============================] - 1s 141us/step - loss: 892.0184 - val_loss: 2237.1345\n",
      "Epoch 112/500\n",
      "4307/4307 [==============================] - 0s 95us/step - loss: 730.1681 - val_loss: 2230.9584\n",
      "Epoch 113/500\n",
      "4307/4307 [==============================] - 0s 97us/step - loss: 740.1911 - val_loss: 2198.2650\n",
      "Epoch 114/500\n",
      "4307/4307 [==============================] - 1s 158us/step - loss: 757.1123 - val_loss: 2211.0101\n",
      "Epoch 115/500\n",
      "4307/4307 [==============================] - 0s 85us/step - loss: 729.0608 - val_loss: 2030.2969\n",
      "Epoch 116/500\n",
      "4307/4307 [==============================] - 0s 89us/step - loss: 662.0585 - val_loss: 2369.9587\n",
      "Epoch 117/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 662.8029 - val_loss: 2112.0198\n",
      "Epoch 118/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 692.2141 - val_loss: 2536.9611\n",
      "Epoch 119/500\n",
      "4307/4307 [==============================] - 0s 91us/step - loss: 670.8254 - val_loss: 3240.1232\n",
      "Epoch 120/500\n",
      "4307/4307 [==============================] - 0s 84us/step - loss: 674.2289 - val_loss: 2145.4035\n",
      "Epoch 121/500\n",
      "4307/4307 [==============================] - 1s 124us/step - loss: 867.6696 - val_loss: 2174.2484\n",
      "Epoch 122/500\n",
      "4307/4307 [==============================] - 0s 95us/step - loss: 752.5704 - val_loss: 2182.7323\n",
      "Epoch 123/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 646.2883 - val_loss: 2539.6075\n",
      "Epoch 124/500\n",
      "4307/4307 [==============================] - 1s 117us/step - loss: 672.2939 - val_loss: 2346.3316\n",
      "Epoch 125/500\n",
      "4307/4307 [==============================] - 1s 121us/step - loss: 724.8564 - val_loss: 2312.2165\n",
      "Epoch 00125: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define modelusing Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=641, activation= \"relu\"))\n",
    "model.add(Dense(100, activation= \"relu\"))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=1e-3, patience=10, verbose=1,mode='auto')\n",
    "hist=model.fit(X_train,y_train, epochs=500, validation_split=0.2,shuffle=True, verbose=1, callbacks=[early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Hist\n",
    "\n",
    "#history_dict=history.history\n",
    "#plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "\n",
    "#history_dict=hist.history\n",
    "loss_values=hist.history['loss']\n",
    "val_loss_values=hist.history['val_loss']\n",
    "plt.plot(loss_values,'bo', label='training loss')\n",
    "plt.plot(val_loss_values,'r', label='validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.67985125565443"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction\n",
    "predictions = model.predict(X_test)\n",
    "annrmse=np.sqrt(mean_squared_error(y_test,predictions))\n",
    "annrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4307 samples, validate on 1077 samples\n",
      "Epoch 1/500\n",
      "4307/4307 [==============================] - 1s 176us/step - loss: 1709261.6398 - val_loss: 121670.6268\n",
      "Epoch 2/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 149915.8661 - val_loss: 44951.4592\n",
      "Epoch 3/500\n",
      "4307/4307 [==============================] - 1s 128us/step - loss: 123060.3281 - val_loss: 29906.5196\n",
      "Epoch 4/500\n",
      "4307/4307 [==============================] - 1s 117us/step - loss: 108620.7006 - val_loss: 25072.8622\n",
      "Epoch 5/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 103600.5721 - val_loss: 20572.6574\n",
      "Epoch 6/500\n",
      "4307/4307 [==============================] - 1s 141us/step - loss: 101896.3923 - val_loss: 23594.7945\n",
      "Epoch 7/500\n",
      "4307/4307 [==============================] - 1s 121us/step - loss: 92868.0190 - val_loss: 15520.0352\n",
      "Epoch 8/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 98251.6503 - val_loss: 17392.6816\n",
      "Epoch 9/500\n",
      "4307/4307 [==============================] - 1s 143us/step - loss: 96720.7221 - val_loss: 15456.8707\n",
      "Epoch 10/500\n",
      "4307/4307 [==============================] - 1s 121us/step - loss: 92205.5832 - val_loss: 13302.9850\n",
      "Epoch 11/500\n",
      "4307/4307 [==============================] - 1s 117us/step - loss: 91323.0536 - val_loss: 12434.3102\n",
      "Epoch 12/500\n",
      "4307/4307 [==============================] - 1s 150us/step - loss: 91661.7207 - val_loss: 13532.2525\n",
      "Epoch 13/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 87413.1274 - val_loss: 11926.7542\n",
      "Epoch 14/500\n",
      "4307/4307 [==============================] - 0s 115us/step - loss: 89981.2902 - val_loss: 15411.3166\n",
      "Epoch 15/500\n",
      "4307/4307 [==============================] - 1s 147us/step - loss: 95154.1322 - val_loss: 11142.8298\n",
      "Epoch 16/500\n",
      "4307/4307 [==============================] - 0s 108us/step - loss: 92367.8448 - val_loss: 10377.3602\n",
      "Epoch 17/500\n",
      "4307/4307 [==============================] - 0s 105us/step - loss: 91744.6656 - val_loss: 16885.4919\n",
      "Epoch 18/500\n",
      "4307/4307 [==============================] - 1s 137us/step - loss: 87135.9977 - val_loss: 20197.7516\n",
      "Epoch 19/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 90123.2699 - val_loss: 10523.2170\n",
      "Epoch 20/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 89766.4388 - val_loss: 9819.5906\n",
      "Epoch 21/500\n",
      "4307/4307 [==============================] - 1s 137us/step - loss: 85018.0762 - val_loss: 14867.1674\n",
      "Epoch 22/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 83373.8470 - val_loss: 8783.4762\n",
      "Epoch 23/500\n",
      "4307/4307 [==============================] - 0s 98us/step - loss: 80049.0710 - val_loss: 8772.1812\n",
      "Epoch 24/500\n",
      "4307/4307 [==============================] - 1s 136us/step - loss: 87918.0464 - val_loss: 18069.5332\n",
      "Epoch 25/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 86736.1742 - val_loss: 9310.6509\n",
      "Epoch 26/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 86438.3091 - val_loss: 17245.8102\n",
      "Epoch 27/500\n",
      "4307/4307 [==============================] - 1s 132us/step - loss: 82439.7210 - val_loss: 9234.5431\n",
      "Epoch 28/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 89735.7628 - val_loss: 10110.2302\n",
      "Epoch 29/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 84034.4082 - val_loss: 17801.0893\n",
      "Epoch 30/500\n",
      "4307/4307 [==============================] - 1s 134us/step - loss: 85100.0636 - val_loss: 11974.8554\n",
      "Epoch 31/500\n",
      "4307/4307 [==============================] - 0s 106us/step - loss: 89964.9385 - val_loss: 13063.6357\n",
      "Epoch 32/500\n",
      "4307/4307 [==============================] - 0s 104us/step - loss: 84697.2206 - val_loss: 9139.0696\n",
      "Epoch 33/500\n",
      "4307/4307 [==============================] - 1s 136us/step - loss: 83319.3738 - val_loss: 8322.9073\n",
      "Epoch 34/500\n",
      "4307/4307 [==============================] - 0s 108us/step - loss: 86907.3883 - val_loss: 8297.0411\n",
      "Epoch 35/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 85603.7895 - val_loss: 13782.3338\n",
      "Epoch 36/500\n",
      "4307/4307 [==============================] - 1s 130us/step - loss: 85521.9466 - val_loss: 7723.2710\n",
      "Epoch 37/500\n",
      "4307/4307 [==============================] - 0s 110us/step - loss: 86886.0243 - val_loss: 7335.9724\n",
      "Epoch 38/500\n",
      "4307/4307 [==============================] - 0s 102us/step - loss: 84440.4988 - val_loss: 14319.2462\n",
      "Epoch 39/500\n",
      "4307/4307 [==============================] - 1s 143us/step - loss: 81726.6906 - val_loss: 8378.7376\n",
      "Epoch 40/500\n",
      "4307/4307 [==============================] - 0s 111us/step - loss: 84306.2387 - val_loss: 7315.2048\n",
      "Epoch 41/500\n",
      "4307/4307 [==============================] - 1s 117us/step - loss: 82922.3822 - val_loss: 7119.0642\n",
      "Epoch 42/500\n",
      "4307/4307 [==============================] - 1s 154us/step - loss: 87659.9717 - val_loss: 7653.4169\n",
      "Epoch 43/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 84579.1614 - val_loss: 11098.4920\n",
      "Epoch 44/500\n",
      "4307/4307 [==============================] - 1s 116us/step - loss: 85869.2384 - val_loss: 11112.5512\n",
      "Epoch 45/500\n",
      "4307/4307 [==============================] - 1s 153us/step - loss: 86589.6207 - val_loss: 13278.0616\n",
      "Epoch 46/500\n",
      "4307/4307 [==============================] - 1s 124us/step - loss: 84570.0086 - val_loss: 17121.9405\n",
      "Epoch 47/500\n",
      "4307/4307 [==============================] - 1s 136us/step - loss: 80745.1485 - val_loss: 9648.5758\n",
      "Epoch 48/500\n",
      "4307/4307 [==============================] - 1s 131us/step - loss: 88157.8503 - val_loss: 7252.1091\n",
      "Epoch 49/500\n",
      "4307/4307 [==============================] - 0s 105us/step - loss: 85055.1303 - val_loss: 13783.0238\n",
      "Epoch 50/500\n",
      "4307/4307 [==============================] - 0s 113us/step - loss: 81849.3785 - val_loss: 8891.2707\n",
      "Epoch 51/500\n",
      "4307/4307 [==============================] - 1s 130us/step - loss: 85833.0591 - val_loss: 17864.3678\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define modelusing Keras with dropout layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=641, activation= \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation= \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=1e-3, patience=10, verbose=1,mode='auto')\n",
    "hist=model.fit(X_train,y_train, epochs=500, validation_split=0.2,shuffle=True, verbose=1, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Hist\n",
    "\n",
    "#history_dict=history.history\n",
    "#plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "\n",
    "#history_dict=hist.history\n",
    "loss_values=hist.history['loss']\n",
    "val_loss_values=hist.history['val_loss']\n",
    "plt.plot(loss_values,'bo', label='training loss')\n",
    "plt.plot(val_loss_values,'r', label='validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.63525805881775"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction\n",
    "predictions = model.predict(X_test)\n",
    "annrmse=np.sqrt(mean_squared_error(y_test,predictions))\n",
    "annrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv('test0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
